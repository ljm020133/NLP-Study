[[Attention]]


[[Transformer]]


[[Neural probabilistic language model]]
---
(first attempt of probability approach)



[[Word2Vec]]
---
Difference with Neural probabilistic language model:
	


[[Overfitting]]

[[BERT]]
WSL, cuda, 
https://wikidocs.net/book/2155
https://sdc-james.gitbook.io/onebook/7.
https://d2l.ai/

[[CLIP]]

2023/10/28:LORA(+ROBERT), GPT, BERT code
	
2023/11/4:Prompt Tuning

AI(Jin Tian), Linear Algebra!, machine learning(Jin Tian), Data base, optimization, STAT342?
COMS 321 Sec1

Eng250(3), math207(linear algebra 3), cs321(3), coms319(3), Gen Ed(3)
7843


Clay Stevens
